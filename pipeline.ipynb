{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082629ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting raw data...\n",
      "\n",
      "--- Analytical Results ---\n",
      "Total number of customers: 17000\n",
      "Total number of offers: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events: 303572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique customers who made a purchase: 0\n",
      "\n",
      "Top 5 most popular offers (by number of completed offers):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------+--------------+\n",
      "|offer_id                        |offer_type|purchase_count|\n",
      "+--------------------------------+----------+--------------+\n",
      "|fafdcd668e3743c1bb461111dcafc2a4|discount  |4927          |\n",
      "|2298d6c36e964ae4a3e7e9706d1fb8c2|discount  |4698          |\n",
      "|9b98b8c7a33c4b65b9aebfe6a799e6d9|bogo      |3926          |\n",
      "|f19421c1d4aa40978ebb69ca19b0e20d|bogo      |3877          |\n",
      "|2906b810c7d4411798c6938adc9daaa5|discount  |3642          |\n",
      "+--------------------------------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average transaction amount: 12.78\n",
      "\n",
      "Number of offers completed vs. not completed:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|offer_completed|completion_count|\n",
      "+---------------+----------------+\n",
      "|              0|          272955|\n",
      "|              1|           30617|\n",
      "+---------------+----------------+\n",
      "\n",
      "\n",
      "Customer distribution by age group:\n",
      "+---------+--------------+\n",
      "|age_group|customer_count|\n",
      "+---------+--------------+\n",
      "|    25-34|          1380|\n",
      "|    35-44|          1869|\n",
      "|    45-54|          3013|\n",
      "|    55-64|          3421|\n",
      "|      65+|          6441|\n",
      "|      <25|           876|\n",
      "+---------+--------------+\n",
      "\n",
      "\n",
      "Offers with highest completion rate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------+------------+----------------+---------------+\n",
      "|offer_id                        |offer_type|total_events|completed_offers|completion_rate|\n",
      "+--------------------------------+----------+------------+----------------+---------------+\n",
      "|4d5c57ea9a6940dd891ad53e9dbe8da0|bogo      |2986        |2986            |100.0          |\n",
      "|9b98b8c7a33c4b65b9aebfe6a799e6d9|bogo      |3926        |3926            |100.0          |\n",
      "|2298d6c36e964ae4a3e7e9706d1fb8c2|discount  |4698        |4698            |100.0          |\n",
      "|2906b810c7d4411798c6938adc9daaa5|discount  |3642        |3642            |100.0          |\n",
      "|fafdcd668e3743c1bb461111dcafc2a4|discount  |4927        |4927            |100.0          |\n",
      "+--------------------------------+----------+------------+----------------+---------------+\n",
      "\n",
      "\n",
      "Top 10 Customers by Lifetime Value (Total Spent):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|         customer_id|       total_spent|\n",
      "+--------------------+------------------+\n",
      "|3c8d541112a74af99...|           1608.69|\n",
      "|f1d65ae63f174b8f8...|           1365.66|\n",
      "|ae6f43089b674728a...|           1327.74|\n",
      "|626df8678e2a4953b...|           1321.42|\n",
      "|73afdeca19e349b98...|           1319.97|\n",
      "|52959f19113e4241a...|1292.8600000000001|\n",
      "|ad1f0a409ae642bc9...|           1258.19|\n",
      "|d240308de0ee4cf8b...|           1251.99|\n",
      "|946fc0d3ecc4492aa...|            1232.4|\n",
      "|6406abad8e2c4b858...|           1211.76|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, count, sum, avg, from_unixtime, to_timestamp, get_json_object, trim, explode, first, from_json\n",
    "from pyspark.sql.types import StructType, StringType, MapType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CafeRewardsDataPipeline\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "customers_file = \"/Users/rafaelcamara/dev/ballastlane/archive/customers.csv\"\n",
    "offers_file = \"/Users/rafaelcamara/dev/ballastlane/archive/offers.csv\"\n",
    "events_file = \"/Users/rafaelcamara/dev/ballastlane/archive/events.csv\"\n",
    "\n",
    "print(\"Ingesting raw data...\")\n",
    "customers_df = spark.read.csv(customers_file, header=True, inferSchema=True)\n",
    "offers_df = spark.read.csv(offers_file, header=True, inferSchema=True)\n",
    "raw_events_df = spark.read.csv(events_file, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Identify if the offer was completed\n",
    "events_df = raw_events_df.withColumn(\n",
    "    \"offer_completed\",\n",
    "    when(trim(col(\"event\")) == \"offer completed\", lit(1)).otherwise(lit(0))\n",
    ")\n",
    "\n",
    "# flatten the JSON structure in the \"value\" column\n",
    "# Explode the map to key-value pairs\n",
    "\n",
    "# Parse the JSON string into a Map\n",
    "value_map_df = events_df.withColumn(\"value_map\", from_json(col(\"value\"), MapType(StringType(), StringType())))\n",
    "\n",
    "exploded_df = value_map_df.select(\n",
    "    \"customer_id\", \n",
    "    \"event\", \n",
    "    explode(\"value_map\").alias(\"key\", \"val\"),\n",
    "    \"time\",\n",
    "    \"offer_completed\"\n",
    ")\n",
    "\n",
    "pivoted_df = exploded_df.groupBy(\"customer_id\", \"event\", \"time\",\"offer_completed\") \\\n",
    "    .pivot(\"key\", [\"offer_id\", \"reward\", \"amount\"]) \\\n",
    "    .agg(first(\"val\"))\n",
    "\n",
    "\n",
    "events_df = pivoted_df.withColumn(\"event_timestamp_readable\", \n",
    "                                             from_unixtime(col(\"time\")))\n",
    "events_df = events_df.withColumn(\"event_datetime\", \n",
    "                                             to_timestamp(col(\"event_timestamp_readable\")))\n",
    "\n",
    "# Join dataframes\n",
    "# Join events with offers to get offer details for each event\n",
    "events_with_offers = offers_df.join(events_df, \"offer_id\", \"left\")\n",
    "\n",
    "\n",
    "customer_with_events = customers_df.join(events_df, \"customer_id\", \"left\")\n",
    "\n",
    "# Join with customers to get customer demographics\n",
    "full_df = customers_df.join(events_with_offers, \"customer_id\", \"left\")\n",
    "\n",
    "# Analytical Questions\n",
    "print(\"\\n--- Analytical Results ---\")\n",
    "\n",
    "# 1. Total number of customers\n",
    "total_customers = customers_df.count()\n",
    "print(f\"Total number of customers: {total_customers}\")\n",
    "\n",
    "# 2. Total number of offers\n",
    "total_offers = offers_df.count()\n",
    "print(f\"Total number of offers: {total_offers}\")\n",
    "\n",
    "# 3. Total number of events\n",
    "total_events = events_df.count()\n",
    "print(f\"Total number of events: {total_events}\")\n",
    "\n",
    "# 4. Number of unique customers who made a purchase\n",
    "unique_purchasing_customers = full_df.filter(col(\"event\") == \"transaction\") \\\n",
    "                                     .select(\"customer_id\").distinct().count()\n",
    "print(f\"Number of unique customers who made a purchase: {unique_purchasing_customers}\")\n",
    "\n",
    "# 5. Top 5 most popular offers (by number of views or purchases)\n",
    "# Assuming popularity is based on purchases within the offer period\n",
    "top_5_offers = full_df.filter(col(\"offer_completed\") == 1) \\\n",
    "                      .groupBy(\"offer_id\", \"offer_type\") \\\n",
    "                      .agg(count(\"offer_id\").alias(\"purchase_count\")) \\\n",
    "                      .orderBy(col(\"purchase_count\").desc()) \\\n",
    "                      .limit(5)\n",
    "print(\"\\nTop 5 most popular offers (by number of completed offers):\")\n",
    "top_5_offers.show(truncate=False)\n",
    "\n",
    "# 6. Average transaction amount\n",
    "# Filter for purchase events only, extract \"amount\" from JSON in \"value\"\n",
    "average_transaction_amount = events_df.filter(col(\"event\") == \"transaction\") \\\n",
    "    .agg(avg(col(\"amount\").cast(\"double\"))).collect()[0][0]\n",
    "    #.agg(avg(get_json_object(col(\"value\"), \"$.amount\").cast(\"double\"))).collect()[0][0]\n",
    "print(f\"Average transaction amount: {average_transaction_amount:.2f}\")\n",
    "\n",
    "# 7. Number of offers completed vs. not completed\n",
    "completion_window = Window.partitionBy(\"offer_completed\")\n",
    "\n",
    "offers_completion_status= events_df.select(\n",
    "    \"offer_completed\",\n",
    "    count(\"*\").over(completion_window).alias(\"completion_count\")\n",
    ").dropDuplicates()\n",
    "\"\"\"\n",
    "offers_completion_status = events_df.groupBy(\"offer_completed\") \\\n",
    "                                   .agg(count(\"offer_id\").alias(\"count\"))\n",
    "\"\"\"                                   \n",
    "print(\"\\nNumber of offers completed vs. not completed:\")\n",
    "offers_completion_status.show()\n",
    "\n",
    "# 8. Distribution of customers by age group\n",
    "# Assuming age is available in customers_df and is numerical\n",
    "# For simplicity, let\\'s define some age groups\n",
    "customers_df = customers_df.withColumn(\"age_group\", \n",
    "                                     when(col(\"age\") < 25, \"<25\") \\\n",
    "                                     .when((col(\"age\") >= 25) & (col(\"age\") < 35), \"25-34\") \\\n",
    "                                     .when((col(\"age\") >= 35) & (col(\"age\") < 45), \"35-44\") \\\n",
    "                                     .when((col(\"age\") >= 45) & (col(\"age\") < 55), \"45-54\") \\\n",
    "                                     .when((col(\"age\") >= 55) & (col(\"age\") < 65), \"55-64\") \\\n",
    "                                     .otherwise(\"65+\"))\n",
    "\n",
    "age_distribution = customers_df.groupBy(\"age_group\").agg(count(\"customer_id\").alias(\"customer_count\")) \\\n",
    "                               .orderBy(\"age_group\")\n",
    "print(\"\\nCustomer distribution by age group:\")\n",
    "age_distribution.show()\n",
    "\n",
    "# 9. Offers with highest completion rate\n",
    "# Calculate total offers viewed/received and completed offers per offer_id\n",
    "offer_summary = full_df.groupBy(\"offer_id\", \"offer_type\") \\\n",
    "                         .agg(count(\"offer_id\").alias(\"total_events\"), \n",
    "                              sum(col(\"offer_completed\")).alias(\"completed_offers\"))\n",
    "\n",
    "offer_completion_rate = offer_summary.withColumn(\n",
    "    \"completion_rate\",\n",
    "    when(col(\"total_events\") != 0, (col(\"completed_offers\") / col(\"total_events\")) * 100).otherwise(None)\n",
    ")\n",
    "\n",
    "highest_completion_rate_offers = offer_completion_rate.orderBy(col(\"completion_rate\").desc()) \\\n",
    "                                                       .limit(5)\n",
    "print(\"\\nOffers with highest completion rate:\")\n",
    "highest_completion_rate_offers.show(truncate=False)\n",
    "\n",
    "# 10. Customer lifetime value (CLV) - simplified: total transaction amount per customer\n",
    "customer_clv = customer_with_events.filter(col(\"event\") == \"transaction\") \\\n",
    "                       .groupBy(\"customer_id\") \\\n",
    "                       .agg(sum(col(\"amount\").cast(\"double\")).alias(\"total_spent\")) \\\n",
    "                       .orderBy(col(\"total_spent\").desc())\n",
    "\n",
    "print(\"\\nTop 10 Customers by Lifetime Value (Total Spent):\")\n",
    "customer_clv.limit(10).show()\n",
    "\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd25cdf",
   "metadata": {},
   "source": [
    "1. Which marketing channel is the most effective in terms of offer completion rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Completion rate by marketing channel:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------------+---------------+\n",
      "|channel|total_events|completed_offers|completion_rate|\n",
      "+-------+------------+----------------+---------------+\n",
      "|mobile |27378       |27378           |100.0          |\n",
      "|email  |30617       |30617           |100.0          |\n",
      "|social |19810       |19810           |100.0          |\n",
      "|web    |27295       |27295           |100.0          |\n",
      "|NULL   |0           |NULL            |NULL           |\n",
      "+-------+------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, explode, regexp_replace\n",
    "\n",
    "# Parse channels JSON string to array\n",
    "channels_schema = ArrayType(StringType())\n",
    "offers_df = offers_df.withColumn(\"channels_clean\", regexp_replace(col(\"channels\"), \"'\", '\"'))\n",
    "offers_df = offers_df.withColumn(\"channels_array\", from_json(col(\"channels_clean\"), channels_schema))\n",
    "\n",
    "# Explode channels into individual rows\n",
    "offers_exploded = offers_df.withColumn(\"channel\", explode(\"channels_array\"))\n",
    "\n",
    "# Join exploded channels with events that include offer_id\n",
    "full_df_with_channels = full_df.join(\n",
    "    offers_exploded.select(\"offer_id\", \"channel\"),\n",
    "    on=\"offer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate completion rate per channel\n",
    "channel_completion = full_df_with_channels.groupBy(\"channel\") \\\n",
    "    .agg(\n",
    "        count(\"offer_id\").alias(\"total_events\"),\n",
    "        sum(\"offer_completed\").alias(\"completed_offers\")\n",
    "    ) \\\n",
    "    .withColumn(\"completion_rate\", (col(\"completed_offers\") / col(\"total_events\")) * 100)\n",
    "\n",
    "print(\"Completion rate by marketing channel:\")\n",
    "channel_completion.orderBy(\"completion_rate\", ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d7442",
   "metadata": {},
   "source": [
    "2. How is the age distribution of customers who completed offers vs. those who did not?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0de867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Age distribution by offer completion status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-----+\n",
      "|age_group|offer_completed|count|\n",
      "+---------+---------------+-----+\n",
      "|    25-34|              0|24785|\n",
      "|    25-34|              1| 2302|\n",
      "|    35-44|              0|32213|\n",
      "|    35-44|              1| 3590|\n",
      "|    45-54|              0|47646|\n",
      "|    45-54|              1| 6121|\n",
      "|    55-64|              0|53487|\n",
      "|    55-64|              1| 7312|\n",
      "|      65+|              0|99236|\n",
      "|      65+|              1| 9946|\n",
      "|      <25|              0|15588|\n",
      "|      <25|              1| 1346|\n",
      "+---------+---------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "customer_with_events = customer_with_events.withColumn(\"age_group\", \n",
    "    when(col(\"age\") < 25, \"<25\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") < 35), \"25-34\")\n",
    "    .when((col(\"age\") >= 35) & (col(\"age\") < 45), \"35-44\")\n",
    "    .when((col(\"age\") >= 45) & (col(\"age\") < 55), \"45-54\")\n",
    "    .when((col(\"age\") >= 55) & (col(\"age\") < 65), \"55-64\")\n",
    "    .otherwise(\"65+\")\n",
    ")\n",
    "\n",
    "age_dist = customer_with_events.groupBy(\"age_group\", \"offer_completed\") \\\n",
    "    .agg(count(\"*\").alias(\"count\")) \\\n",
    "    .orderBy(\"age_group\", \"offer_completed\")\n",
    "\n",
    "print(\"Age distribution by offer completion status:\")\n",
    "age_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What is the average time taken by customers to complete an offer after receiving it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07097f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:>                                                        (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No matches found between offer received and completed events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "from pyspark.sql.functions import from_unixtime, to_timestamp\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "value_schema = StructType().add(\"offer_id\", StringType())\n",
    "\n",
    "events_df = events_df.withColumn(\"event_timestamp_readable\", from_unixtime(col(\"time\")))\n",
    "events_df = events_df.withColumn(\"event_datetime\", to_timestamp(col(\"event_timestamp_readable\")))\n",
    "\n",
    "received_df = events_df.filter(col(\"event\") == \"offer received\") \\\n",
    "    .select(\"customer_id\", \"offer_id\", col(\"event_datetime\").alias(\"received_time\"))\n",
    "\n",
    "completed_df = events_df.filter(col(\"event\") == \"offer completed\") \\\n",
    "    .select(\"customer_id\", \"offer_id\", col(\"event_datetime\").alias(\"completed_time\"))\n",
    "\n",
    "offer_timings = received_df.join(completed_df, [\"customer_id\", \"offer_id\"], \"inner\") \\\n",
    "    .withColumn(\"completion_duration_hours\",\n",
    "                (col(\"completed_time\").cast(\"long\") - col(\"received_time\").cast(\"long\")) / 3600)\n",
    "\n",
    "result = offer_timings.agg(avg(\"completion_duration_hours\")).collect()[0][0]\n",
    "\n",
    "if result is not None:\n",
    "    print(f\" Average time taken to complete an offer: {result:.2f} hours\")\n",
    "else:\n",
    "    print(\" No matches found between offer received and completed events.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
